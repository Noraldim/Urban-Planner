# Land Segmentation & Smart City Planning

![Python](https://img.shields.io/badge/Python-3.10-blue) ![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15-orange) ![Keras](https://img.shields.io/badge/Keras-DeepLearning-red) ![OpenCV](https://img.shields.io/badge/OpenCV-ComputerVision-green)

## ğŸ“– Project Overview
This project focuses on **Semantic Segmentation** of satellite imagery to identify empty land suitable for construction. Using deep learning, we compare multiple state-of-the-art architectures (**U-Net** vs. **DeepLabV3+**) across various powerful backbones (**ResNet, VGG16, Xception, EfficientNet**).

The final output is not just a mask, but a **Smart City Plan** generated by an algorithmic planner that automatically distributes buildings (Hospitals, Stadiums, Malls) onto the detected empty land based on urban planning rules.
![U-Net Result](assets/Algo_starc.png)

---

## Dataset
* **Source:** Custom Satellite Imagery Dataset (PASTIS/Fixed).
* **Input Size:** 160x160 (Resized for compatibility with ResNet/VGG pooling layers).
* **Classes:** Binary Segmentation.
    * **0 (Black):** Occupied/Non-buildable area.
    * **1 (White):** Empty/Buildable land.
* **Preprocessing:** Images were normalized and processed according to the specific requirements of each backbone (e.g., `preprocess_input` for ResNet vs VGG).

---

## Model Architectures & Experimentation

We conducted a rigorous comparison between two primary segmentation architectures with various pre-trained encoders (backbones).

### 1. U-Net (Encoder-Decoder)
U-Net is the standard for medical and fine-grained segmentation. We trained it using **ResNet34**, **ResNet101**, and **VGG16**.

![U-Net Result](assets/U-net_main.png)
*Figure 1: Segmentation results using U-Net architecture.*

### 2. DeepLabV3+ (Spatial Pyramid Pooling)
DeepLabV3+ uses Atrous Spatial Pyramid Pooling (ASPP) to capture multi-scale context. We trained custom implementations using multiple backbones.

#### DeepLabV3+ with ResNet50
![DeepLab ResNet50](assets/DeepLab_resnet50.png)

#### DeepLabV3+ with ResNet101
![DeepLab ResNet101](assets/DeepLap_ResNet101.png)

#### DeepLabV3+ with Xception
![DeepLab Xception](assets/DeepLapV3_%20Xception.png)

#### DeepLabV3+ with EfficientNetB5 (Best Performer)
![DeepLab EfficientNetB5](assets/DeepLabV3_EfficientNetB5.png)

---

## ğŸ“Š Performance Comparison
Below is the evaluation summary of all trained models.

| Model | Backbone | Mean IoU | F1 Score (Dice) | Pixel Accuracy | Precision | Recall |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| **U-Net** | ResNet34 | *[Insert]* | *[Insert]* | *[Insert]* | *[Insert]* | *[Insert]* |
| **U-Net** | ResNet101 | *[Insert]* | *[Insert]* | *[Insert]* | *[Insert]* | *[Insert]* |
| **U-Net** | VGG16 | *[Insert]* | *[Insert]* | *[Insert]* | *[Insert]* | *[Insert]* |
| **DeepLabV3+** | ResNet50 | *0.8877* | *0.9392* | *0.9390* | *0.9424* | *0.9372* |
| **DeepLabV3+** | ResNet101 | *0.9372* | *0.9372* | *0.9432* | *0.9363* | *0.9538* |
| **DeepLabV3+** | Xception | *0.8659* | *0.9257* | *0.9261* | *0.9154* | *0.9385* |
| **DeepLabV3+** | EfficientNetB5 | *0.8784* | *0.9335* | *0.9323* | *0.9210* | *0.9488* |

> **Key Findings:**
> * **DeepLabV3+ (xx)** achieved the highest overall accuracy due to its robust feature extraction.
> * **U-Net (xx)** performed exceptionally well on boundaries but required significantly more GPU memory.
> * **Xception** offered the best balance between speed and accuracy.

---

## File Structure

```bash
â”œâ”€â”€ assets/             
â”‚   â”œâ”€â”€ DeepLabV3_EfficientNetB5.png
â”‚   â”œâ”€â”€ DeepLab_resnet50.png
â”‚   â”œâ”€â”€ DeepLapV3_ Xception.png
â”‚   â”œâ”€â”€ DeepLap_ResNet101.png
â”‚   â””â”€â”€ U-net_main.png
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/          
â”‚   â””â”€â”€ masks/           
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ train_unet.py
â”‚   â”œâ”€â”€ train_unet.py
â”‚   â”œâ”€â”€ train_unet.py
â”‚   â”œâ”€â”€ train_unet.py
â”‚   â”œâ”€â”€ train_unet.py
â”‚   â”œâ”€â”€ train_unet.py
â”‚   â”œâ”€â”€ train_deeplab.py 
â”‚   â””â”€â”€ evaluate.py     
â”œâ”€â”€ city_planner.py      
â”œâ”€â”€ README.md            # This file
â””â”€â”€ requirements.txt
```

---

## Application: The Smart City Planner
Beyond segmentation, this repository includes a post-processing algorithm that takes the AI-generated mask and plans a city layout.

### How it Works:
1.  **Land Analysis:** Calculates total available square meters from the mask.
2.  **Feasibility Check:** Compares available land vs. required land for the blueprint.
3.  **Conflict-Free Placement:** Uses a randomized spatial search to place buildings without overlapping existing structures or detecting collision with boundaries.
4.  **Priority Handling:** Prioritizes critical infrastructure (Hospitals, Stadiums) before placing residential units.

### Blueprint Config
The system currently places:
* ğŸŸï¸ **Stadiums** (Red)
* ğŸ¥ **Hospitals** (Cyan)
* ğŸ›ï¸ **Malls** (Magenta)
* ğŸ•Œ **Mosques** (Yellow)
* ğŸ  **Residential Units** (Green)

---

##  Installation & Usage

### 1. Install Dependencies
```bash
pip install tensorflow keras opencv-python matplotlib segmentation-models scikit-learn patchify
